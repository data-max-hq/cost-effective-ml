{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "165c2e6e-af8f-4a52-aef8-e7ce61c6c76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray==2.5.1 in /opt/conda/lib/python3.8/site-packages (2.5.1)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.8/site-packages (12.0.1)\n",
      "Collecting tblib\n",
      "  Downloading tblib-2.0.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (3.12.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (7.1.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (1.22.4)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (4.23.3)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (3.2.0)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (1.3.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (2.28.2)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (1.3.1)\n",
      "Requirement already satisfied: grpcio<=1.51.3,>=1.32.0 in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (1.51.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (1.0.5)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (22.2.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from ray==2.5.1) (5.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.4.13)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (66.1.1)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/conda/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->ray==2.5.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->ray==2.5.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->ray==2.5.1) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->ray==2.5.1) (2.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->ray==2.5.1) (0.19.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow) (3.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Installing collected packages: tblib\n",
      "Successfully installed tblib-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ray==2.5.1 tensorflow pyarrow tblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15a5bcb-c809-41a0-8b15-a79a53055c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from filelock import FileLock\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from ray.air.result import Result\n",
    "import tensorflow as tf\n",
    "\n",
    "from ray.train.tensorflow import TensorflowTrainer\n",
    "from ray.air.integrations.keras import ReportCheckpointCallback\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "\n",
    "def mnist_dataset(batch_size: int) -> tf.data.Dataset:\n",
    "    with FileLock(os.path.expanduser(\"~/.mnist_lock\")):\n",
    "        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        .shuffle(60000)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def build_cnn_model() -> tf.keras.Model:\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(28, 28)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_func(config: dict):\n",
    "    per_worker_batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "    steps_per_epoch = config.get(\"steps_per_epoch\", 70)\n",
    "\n",
    "    tf_config = json.loads(os.environ[\"TF_CONFIG\"])\n",
    "    num_workers = len(tf_config[\"cluster\"][\"worker\"])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_cnn_model()\n",
    "        learning_rate = config.get(\"lr\", 0.001)\n",
    "        multi_worker_model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "    history = multi_worker_model.fit(\n",
    "        multi_worker_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[ReportCheckpointCallback()],\n",
    "    )\n",
    "    results = history.history\n",
    "    return results\n",
    "\n",
    "\n",
    "def train_tensorflow_mnist(\n",
    "    num_workers: int = 2, use_gpu: bool = False, epochs: int = 4\n",
    ") -> Result:\n",
    "    config = {\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": epochs}\n",
    "    trainer = TensorflowTrainer(\n",
    "        train_loop_per_worker=train_func,\n",
    "        train_loop_config=config,\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "    )\n",
    "    results = trainer.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7d7155-0829-4b5d-8675-5c865d7198d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6d4f72-fb11-4bfe-928f-4c58a1cd0ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Ray Client is already connected. Maybe you called ray.init(\"ray://<address>\") twice by accident?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mray://example-cluster-head-svc:10001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/_private/worker.py:1359\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m passed_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1358\u001b[0m builder\u001b[38;5;241m.\u001b[39m_init_args(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpassed_kwargs)\n\u001b[0;32m-> 1359\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01musage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m usage_lib\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m passed_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_multiple\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/client_builder.py:182\u001b[0m, in \u001b[0;36mClientBuilder.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_multiple_connections:\n\u001b[1;32m    180\u001b[0m     old_ray_cxt \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mray\u001b[38;5;241m.\u001b[39mset_context(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 182\u001b[0m client_info_dict \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_connect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_job_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_credentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_init_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote_init_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m dashboard_url \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mray\u001b[38;5;241m.\u001b[39m_get_dashboard_url()\n\u001b[1;32m    192\u001b[0m cxt \u001b[38;5;241m=\u001b[39m ClientContext(\n\u001b[1;32m    193\u001b[0m     dashboard_url\u001b[38;5;241m=\u001b[39mdashboard_url,\n\u001b[1;32m    194\u001b[0m     python_version\u001b[38;5;241m=\u001b[39mclient_info_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython_version\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     _context_to_restore\u001b[38;5;241m=\u001b[39mray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mray\u001b[38;5;241m.\u001b[39mget_context(),\n\u001b[1;32m    200\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client_connect.py:44\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(conn_str, secure, metadata, connection_retries, job_config, namespace, ignore_version, _credentials, ray_init_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling ray.init() again after it has already been called. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReusing the existing Ray client connection.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mclient_worker\u001b[38;5;241m.\u001b[39mconnection_info()\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRay Client is already connected. Maybe you called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mray.init(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray://<address>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) twice by accident?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Enable the same hooks that RAY_CLIENT_MODE does, as calling\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# ray.init(\"ray://<address>\") is specifically for using client mode.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m _set_client_hook_status(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Ray Client is already connected. Maybe you called ray.init(\"ray://<address>\") twice by accident?"
     ]
    }
   ],
   "source": [
    "ray.init(address=\"ray://example-cluster-head-svc:10001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672995c-a4b6-4715-a2f6-5fadeb7dc507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m 2023-06-30 04:56:57.633525: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m 2023-06-30 04:56:57.836576: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m 2023-06-30 04:56:59.050186: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m 2023-06-30 04:56:59.050331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m 2023-06-30 04:56:59.050350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/tune/impl/tuner_internal.py:147: UserWarning: Executing `.fit()` may leave less than 20% of CPUs in this cluster for Dataset execution, which can lead to resource contention or hangs. To avoid this, reserve at least 20% of node CPUs for Dataset execution by setting `_max_cpu_fraction_per_node = 0.8` in the Trainer scaling_config. See https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune for more info.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   self._maybe_warn_resource_contention()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-06-30 04:58:34</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:31.16        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.5/47.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/1 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TensorflowTrainer_38bb7_00000</td><td>RUNNING </td><td>10.42.0.75:665</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         72.4023</td><td style=\"text-align: right;\">2.2017</td><td style=\"text-align: right;\">  0.455357</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=665)\u001b[0m 2023-06-30 04:57:08.195744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "\u001b[2m\u001b[36m(pid=665)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=665)\u001b[0m 2023-06-30 04:57:08.457044: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(pid=665)\u001b[0m 2023-06-30 04:57:09.941149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=665)\u001b[0m 2023-06-30 04:57:09.941284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=665)\u001b[0m 2023-06-30 04:57:09.941299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(TensorflowTrainer pid=665)\u001b[0m 2023-06-30 04:57:18,633\tINFO backend_executor.py:137 -- Starting distributed worker processes: ['879 (10.42.0.75)', '934 (10.42.0.75)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:18.743418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:18.738272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:19.254063: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:19.322165: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:22.321713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:22.321813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:22.321824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:22.430704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:22.430822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:22.430833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:26.347725: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:26.347770: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:26.347731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:26.347776: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "   16384/11490434 [..............................] - ETA: 41s\n",
      "   49152/11490434 [..............................] - ETA: 36s\n",
      "   81920/11490434 [..............................] - ETA: 35s\n",
      "  212992/11490434 [..............................] - ETA: 19s\n",
      "  475136/11490434 [>.............................] - ETA: 10s\n",
      " 1048576/11490434 [=>............................] - ETA: 5s\n",
      " 2383872/11490434 [=====>........................] - ETA: 2s\n",
      " 5488640/11490434 [=============>................] - ETA: 0s\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:32.421919: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m op: \"TensorSliceDataset\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m input: \"Placeholder/_0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m input: \"Placeholder/_1\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   key: \"Toutput_types\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       type: DT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       type: DT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   key: \"_cardinality\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     i: 60000\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   key: \"is_files\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   key: \"metadata\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     s: \"\\n\\024TensorSliceDataset:0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   key: \"output_shapes\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   key: \"replicate_on_split\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m experimental_type {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     type_id: TFT_DATASET\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m           type_id: TFT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m           type_id: TFT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:32.441136: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m op: \"TensorSliceDataset\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m input: \"Placeholder/_0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m input: \"Placeholder/_1\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   key: \"Toutput_types\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       type: DT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       type: DT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   key: \"_cardinality\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     i: 60000\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   key: \"is_files\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   key: \"metadata\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     s: \"\\n\\024TensorSliceDataset:0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   key: \"output_shapes\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   key: \"replicate_on_split\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m experimental_type {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     type_id: TFT_DATASET\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m           type_id: TFT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m           type_id: TFT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m 2023-06-30 04:57:33.022697: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m 2023-06-30 04:57:33.119068: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m Epoch 1/100\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m Epoch 1/100\n",
      " 1/70 [..............................] - ETA: 4:50 - loss: 4.5964 - accuracy: 0.2656\n",
      " 1/70 [..............................] - ETA: 4:43 - loss: 4.5964 - accuracy: 0.2656\n",
      " 2/70 [..............................] - ETA: 27s - loss: 4.6122 - accuracy: 0.2188 \n",
      " 2/70 [..............................] - ETA: 27s - loss: 4.6122 - accuracy: 0.2188 \n",
      " 3/70 [>.............................] - ETA: 27s - loss: 4.6226 - accuracy: 0.1771\n",
      " 3/70 [>.............................] - ETA: 26s - loss: 4.6226 - accuracy: 0.1771\n",
      " 4/70 [>.............................] - ETA: 26s - loss: 4.6151 - accuracy: 0.2070\n",
      " 4/70 [>.............................] - ETA: 26s - loss: 4.6151 - accuracy: 0.2070\n",
      " 5/70 [=>............................] - ETA: 24s - loss: 4.6133 - accuracy: 0.2125\n",
      " 5/70 [=>............................] - ETA: 24s - loss: 4.6133 - accuracy: 0.2125\n",
      " 6/70 [=>............................] - ETA: 23s - loss: 4.6110 - accuracy: 0.2292\n",
      " 6/70 [=>............................] - ETA: 23s - loss: 4.6110 - accuracy: 0.2292\n",
      " 7/70 [==>...........................] - ETA: 22s - loss: 4.6120 - accuracy: 0.2254\n",
      " 7/70 [==>...........................] - ETA: 22s - loss: 4.6120 - accuracy: 0.2254\n",
      " 8/70 [==>...........................] - ETA: 21s - loss: 4.6133 - accuracy: 0.2266\n",
      " 8/70 [==>...........................] - ETA: 21s - loss: 4.6133 - accuracy: 0.2266\n",
      " 9/70 [==>...........................] - ETA: 20s - loss: 4.6135 - accuracy: 0.2188\n",
      " 9/70 [==>...........................] - ETA: 20s - loss: 4.6135 - accuracy: 0.2188\n",
      "10/70 [===>..........................] - ETA: 20s - loss: 4.6138 - accuracy: 0.2234\n",
      "10/70 [===>..........................] - ETA: 20s - loss: 4.6138 - accuracy: 0.2234\n",
      "11/70 [===>..........................] - ETA: 20s - loss: 4.6100 - accuracy: 0.2358\n",
      "11/70 [===>..........................] - ETA: 20s - loss: 4.6100 - accuracy: 0.2358\n",
      "12/70 [====>.........................] - ETA: 20s - loss: 4.6099 - accuracy: 0.2357\n",
      "12/70 [====>.........................] - ETA: 20s - loss: 4.6099 - accuracy: 0.2357\n",
      "13/70 [====>.........................] - ETA: 19s - loss: 4.6085 - accuracy: 0.2392\n",
      "13/70 [====>.........................] - ETA: 19s - loss: 4.6085 - accuracy: 0.2392\n",
      "14/70 [=====>........................] - ETA: 19s - loss: 4.6048 - accuracy: 0.2489\n",
      "14/70 [=====>........................] - ETA: 19s - loss: 4.6048 - accuracy: 0.2489\n",
      "15/70 [=====>........................] - ETA: 18s - loss: 4.6042 - accuracy: 0.2510\n",
      "15/70 [=====>........................] - ETA: 18s - loss: 4.6042 - accuracy: 0.2510\n",
      "16/70 [=====>........................] - ETA: 18s - loss: 4.6039 - accuracy: 0.2490\n",
      "16/70 [=====>........................] - ETA: 18s - loss: 4.6039 - accuracy: 0.2490\n",
      "17/70 [======>.......................] - ETA: 17s - loss: 4.6013 - accuracy: 0.2528\n",
      "17/70 [======>.......................] - ETA: 17s - loss: 4.6013 - accuracy: 0.2528\n",
      "18/70 [======>.......................] - ETA: 17s - loss: 4.6004 - accuracy: 0.2578\n",
      "18/70 [======>.......................] - ETA: 17s - loss: 4.6004 - accuracy: 0.2578\n",
      "19/70 [=======>......................] - ETA: 17s - loss: 4.5999 - accuracy: 0.2599\n",
      "19/70 [=======>......................] - ETA: 17s - loss: 4.5999 - accuracy: 0.2599\n",
      "20/70 [=======>......................] - ETA: 16s - loss: 4.5992 - accuracy: 0.2633\n",
      "20/70 [=======>......................] - ETA: 16s - loss: 4.5992 - accuracy: 0.2633\n",
      "21/70 [========>.....................] - ETA: 16s - loss: 4.5976 - accuracy: 0.2641\n",
      "21/70 [========>.....................] - ETA: 16s - loss: 4.5976 - accuracy: 0.2641\n",
      "22/70 [========>.....................] - ETA: 16s - loss: 4.5945 - accuracy: 0.2699\n",
      "22/70 [========>.....................] - ETA: 16s - loss: 4.5945 - accuracy: 0.2699\n",
      "23/70 [========>.....................] - ETA: 16s - loss: 4.5932 - accuracy: 0.2738\n",
      "23/70 [========>.....................] - ETA: 16s - loss: 4.5932 - accuracy: 0.2738\n",
      "24/70 [=========>....................] - ETA: 15s - loss: 4.5914 - accuracy: 0.2767\n",
      "24/70 [=========>....................] - ETA: 15s - loss: 4.5914 - accuracy: 0.2767\n",
      "25/70 [=========>....................] - ETA: 15s - loss: 4.5892 - accuracy: 0.2844\n",
      "25/70 [=========>....................] - ETA: 15s - loss: 4.5892 - accuracy: 0.2844\n",
      "26/70 [==========>...................] - ETA: 14s - loss: 4.5880 - accuracy: 0.2927\n",
      "26/70 [==========>...................] - ETA: 14s - loss: 4.5880 - accuracy: 0.2927\n",
      "27/70 [==========>...................] - ETA: 14s - loss: 4.5878 - accuracy: 0.2951\n",
      "27/70 [==========>...................] - ETA: 14s - loss: 4.5878 - accuracy: 0.2951\n",
      "28/70 [===========>..................] - ETA: 14s - loss: 4.5864 - accuracy: 0.2991\n",
      "28/70 [===========>..................] - ETA: 14s - loss: 4.5864 - accuracy: 0.2991\n",
      "29/70 [===========>..................] - ETA: 13s - loss: 4.5851 - accuracy: 0.3050\n",
      "29/70 [===========>..................] - ETA: 13s - loss: 4.5851 - accuracy: 0.3050\n",
      "30/70 [===========>..................] - ETA: 13s - loss: 4.5843 - accuracy: 0.3073\n",
      "30/70 [===========>..................] - ETA: 13s - loss: 4.5843 - accuracy: 0.3073\n",
      "31/70 [============>.................] - ETA: 12s - loss: 4.5835 - accuracy: 0.3110\n",
      "31/70 [============>.................] - ETA: 12s - loss: 4.5835 - accuracy: 0.3110\n",
      "32/70 [============>.................] - ETA: 12s - loss: 4.5828 - accuracy: 0.3125\n",
      "32/70 [============>.................] - ETA: 12s - loss: 4.5828 - accuracy: 0.3125\n",
      "33/70 [=============>................] - ETA: 12s - loss: 4.5807 - accuracy: 0.3215\n",
      "33/70 [=============>................] - ETA: 12s - loss: 4.5807 - accuracy: 0.3215\n",
      "34/70 [=============>................] - ETA: 12s - loss: 4.5796 - accuracy: 0.3272\n",
      "34/70 [=============>................] - ETA: 12s - loss: 4.5796 - accuracy: 0.3272\n",
      "35/70 [==============>...............] - ETA: 11s - loss: 4.5789 - accuracy: 0.3313\n",
      "35/70 [==============>...............] - ETA: 11s - loss: 4.5789 - accuracy: 0.3313\n",
      "36/70 [==============>...............] - ETA: 11s - loss: 4.5766 - accuracy: 0.3364\n",
      "36/70 [==============>...............] - ETA: 11s - loss: 4.5766 - accuracy: 0.3364\n",
      "37/70 [==============>...............] - ETA: 10s - loss: 4.5760 - accuracy: 0.3391\n",
      "37/70 [==============>...............] - ETA: 10s - loss: 4.5760 - accuracy: 0.3391\n",
      "38/70 [===============>..............] - ETA: 10s - loss: 4.5751 - accuracy: 0.3425\n",
      "38/70 [===============>..............] - ETA: 10s - loss: 4.5751 - accuracy: 0.3425\n",
      "39/70 [===============>..............] - ETA: 10s - loss: 4.5734 - accuracy: 0.3490\n",
      "39/70 [===============>..............] - ETA: 10s - loss: 4.5734 - accuracy: 0.3490\n",
      "40/70 [================>.............] - ETA: 9s - loss: 4.5727 - accuracy: 0.3512 \n",
      "40/70 [================>.............] - ETA: 9s - loss: 4.5727 - accuracy: 0.3512 \n",
      "41/70 [================>.............] - ETA: 9s - loss: 4.5717 - accuracy: 0.3556\n",
      "41/70 [================>.............] - ETA: 9s - loss: 4.5717 - accuracy: 0.3556\n",
      "42/70 [=================>............] - ETA: 9s - loss: 4.5704 - accuracy: 0.3586\n",
      "42/70 [=================>............] - ETA: 9s - loss: 4.5704 - accuracy: 0.3586\n",
      "43/70 [=================>............] - ETA: 9s - loss: 4.5698 - accuracy: 0.3612\n",
      "43/70 [=================>............] - ETA: 9s - loss: 4.5698 - accuracy: 0.3612\n",
      "44/70 [=================>............] - ETA: 8s - loss: 4.5690 - accuracy: 0.3626\n",
      "44/70 [=================>............] - ETA: 8s - loss: 4.5690 - accuracy: 0.3626\n",
      "45/70 [==================>...........] - ETA: 8s - loss: 4.5680 - accuracy: 0.3670\n",
      "45/70 [==================>...........] - ETA: 8s - loss: 4.5680 - accuracy: 0.3670\n",
      "46/70 [==================>...........] - ETA: 7s - loss: 4.5671 - accuracy: 0.3719\n",
      "46/70 [==================>...........] - ETA: 7s - loss: 4.5671 - accuracy: 0.3719\n",
      "47/70 [===================>..........] - ETA: 7s - loss: 4.5660 - accuracy: 0.3777\n",
      "47/70 [===================>..........] - ETA: 7s - loss: 4.5660 - accuracy: 0.3777\n",
      "48/70 [===================>..........] - ETA: 7s - loss: 4.5656 - accuracy: 0.3812\n",
      "48/70 [===================>..........] - ETA: 7s - loss: 4.5656 - accuracy: 0.3812\n",
      "49/70 [====================>.........] - ETA: 6s - loss: 4.5646 - accuracy: 0.3849\n",
      "49/70 [====================>.........] - ETA: 6s - loss: 4.5646 - accuracy: 0.3849\n",
      "50/70 [====================>.........] - ETA: 6s - loss: 4.5636 - accuracy: 0.3881\n",
      "50/70 [====================>.........] - ETA: 6s - loss: 4.5636 - accuracy: 0.3881\n",
      "51/70 [====================>.........] - ETA: 6s - loss: 4.5629 - accuracy: 0.3925\n",
      "51/70 [====================>.........] - ETA: 6s - loss: 4.5629 - accuracy: 0.3925\n",
      "52/70 [=====================>........] - ETA: 5s - loss: 4.5621 - accuracy: 0.3936\n",
      "52/70 [=====================>........] - ETA: 5s - loss: 4.5621 - accuracy: 0.3936\n",
      "53/70 [=====================>........] - ETA: 5s - loss: 4.5613 - accuracy: 0.3980\n",
      "53/70 [=====================>........] - ETA: 5s - loss: 4.5613 - accuracy: 0.3980\n",
      "54/70 [======================>.......] - ETA: 5s - loss: 4.5602 - accuracy: 0.4019\n",
      "54/70 [======================>.......] - ETA: 5s - loss: 4.5602 - accuracy: 0.4019\n",
      "55/70 [======================>.......] - ETA: 4s - loss: 4.5590 - accuracy: 0.4080\n",
      "55/70 [======================>.......] - ETA: 4s - loss: 4.5590 - accuracy: 0.4080\n",
      "56/70 [=======================>......] - ETA: 4s - loss: 4.5577 - accuracy: 0.4129\n",
      "56/70 [=======================>......] - ETA: 4s - loss: 4.5577 - accuracy: 0.4129\n",
      "57/70 [=======================>......] - ETA: 4s - loss: 4.5569 - accuracy: 0.4164\n",
      "57/70 [=======================>......] - ETA: 4s - loss: 4.5569 - accuracy: 0.4164\n",
      "58/70 [=======================>......] - ETA: 3s - loss: 4.5558 - accuracy: 0.4205\n",
      "58/70 [=======================>......] - ETA: 3s - loss: 4.5558 - accuracy: 0.4205\n",
      "59/70 [========================>.....] - ETA: 3s - loss: 4.5550 - accuracy: 0.4253\n",
      "59/70 [========================>.....] - ETA: 3s - loss: 4.5550 - accuracy: 0.4253\n",
      "60/70 [========================>.....] - ETA: 3s - loss: 4.5538 - accuracy: 0.4297\n",
      "60/70 [========================>.....] - ETA: 3s - loss: 4.5538 - accuracy: 0.4297\n",
      "61/70 [=========================>....] - ETA: 2s - loss: 4.5524 - accuracy: 0.4339\n",
      "61/70 [=========================>....] - ETA: 2s - loss: 4.5524 - accuracy: 0.4339\n",
      "62/70 [=========================>....] - ETA: 2s - loss: 4.5516 - accuracy: 0.4362\n",
      "62/70 [=========================>....] - ETA: 2s - loss: 4.5516 - accuracy: 0.4362\n",
      "63/70 [==========================>...] - ETA: 2s - loss: 4.5502 - accuracy: 0.4407\n",
      "63/70 [==========================>...] - ETA: 2s - loss: 4.5502 - accuracy: 0.4407\n",
      "64/70 [==========================>...] - ETA: 1s - loss: 4.5495 - accuracy: 0.4429\n",
      "64/70 [==========================>...] - ETA: 1s - loss: 4.5495 - accuracy: 0.4429\n",
      "65/70 [==========================>...] - ETA: 1s - loss: 4.5489 - accuracy: 0.4454\n",
      "65/70 [==========================>...] - ETA: 1s - loss: 4.5489 - accuracy: 0.4454\n",
      "66/70 [===========================>..] - ETA: 1s - loss: 4.5483 - accuracy: 0.4484\n",
      "66/70 [===========================>..] - ETA: 1s - loss: 4.5483 - accuracy: 0.4484\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 4.5472 - accuracy: 0.4531\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 4.5472 - accuracy: 0.4531\n",
      "68/70 [============================>.] - ETA: 0s - loss: 4.5459 - accuracy: 0.4577\n",
      "68/70 [============================>.] - ETA: 0s - loss: 4.5459 - accuracy: 0.4577\n",
      "69/70 [============================>.] - ETA: 0s - loss: 4.5450 - accuracy: 0.4604\n",
      "69/70 [============================>.] - ETA: 0s - loss: 4.5450 - accuracy: 0.4604\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.5444 - accuracy: 0.4623\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.5444 - accuracy: 0.4623\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m Result for TensorflowTrainer_38bb7_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   accuracy: 0.23113839328289032\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   date: 2023-06-30_04-58-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   hostname: example-cluster-head-vxm8k\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   loss: 2.2722084522247314\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   node_ip: 10.42.0.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   pid: 665\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   time_since_restore: 48.73028326034546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   time_this_iter_s: 48.73028326034546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   time_total_s: 48.73028326034546\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   timestamp: 1688126280\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   trial_id: 38bb7_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   \n",
      "70/70 [==============================] - 27s 336ms/step - loss: 2.2722 - accuracy: 0.2311\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m Epoch 2/100\n",
      "70/70 [==============================] - 27s 336ms/step - loss: 2.2722 - accuracy: 0.2311\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m Epoch 2/100\n",
      " 1/70 [..............................] - ETA: 33s - loss: 4.4735 - accuracy: 0.6719\n",
      " 1/70 [..............................] - ETA: 33s - loss: 4.4735 - accuracy: 0.6719\n",
      " 2/70 [..............................] - ETA: 27s - loss: 4.4775 - accuracy: 0.7109\n",
      " 2/70 [..............................] - ETA: 27s - loss: 4.4775 - accuracy: 0.7109\n",
      " 3/70 [>.............................] - ETA: 23s - loss: 4.4719 - accuracy: 0.6979\n",
      " 3/70 [>.............................] - ETA: 23s - loss: 4.4719 - accuracy: 0.6979\n",
      " 4/70 [>.............................] - ETA: 22s - loss: 4.4709 - accuracy: 0.6953\n",
      " 4/70 [>.............................] - ETA: 22s - loss: 4.4709 - accuracy: 0.6953\n",
      " 5/70 [=>............................] - ETA: 21s - loss: 4.4660 - accuracy: 0.7188\n",
      " 5/70 [=>............................] - ETA: 21s - loss: 4.4660 - accuracy: 0.7188\n",
      " 6/70 [=>............................] - ETA: 21s - loss: 4.4671 - accuracy: 0.7292\n",
      " 6/70 [=>............................] - ETA: 21s - loss: 4.4671 - accuracy: 0.7292\n",
      " 7/70 [==>...........................] - ETA: 20s - loss: 4.4692 - accuracy: 0.7388\n",
      " 7/70 [==>...........................] - ETA: 20s - loss: 4.4692 - accuracy: 0.7388\n",
      " 8/70 [==>...........................] - ETA: 19s - loss: 4.4690 - accuracy: 0.7383\n",
      " 8/70 [==>...........................] - ETA: 19s - loss: 4.4690 - accuracy: 0.7383\n",
      " 9/70 [==>...........................] - ETA: 19s - loss: 4.4641 - accuracy: 0.7552\n",
      " 9/70 [==>...........................] - ETA: 19s - loss: 4.4641 - accuracy: 0.7552\n",
      "10/70 [===>..........................] - ETA: 18s - loss: 4.4623 - accuracy: 0.7563\n",
      "10/70 [===>..........................] - ETA: 18s - loss: 4.4623 - accuracy: 0.7563\n",
      "11/70 [===>..........................] - ETA: 18s - loss: 4.4622 - accuracy: 0.7457\n",
      "11/70 [===>..........................] - ETA: 18s - loss: 4.4622 - accuracy: 0.7457\n",
      "12/70 [====>.........................] - ETA: 18s - loss: 4.4611 - accuracy: 0.7539\n",
      "12/70 [====>.........................] - ETA: 18s - loss: 4.4611 - accuracy: 0.7539\n",
      "13/70 [====>.........................] - ETA: 18s - loss: 4.4615 - accuracy: 0.7476\n",
      "13/70 [====>.........................] - ETA: 18s - loss: 4.4615 - accuracy: 0.7476\n",
      "14/70 [=====>........................] - ETA: 18s - loss: 4.4591 - accuracy: 0.7567\n",
      "14/70 [=====>........................] - ETA: 18s - loss: 4.4591 - accuracy: 0.7567\n",
      "15/70 [=====>........................] - ETA: 17s - loss: 4.4578 - accuracy: 0.7604\n",
      "15/70 [=====>........................] - ETA: 17s - loss: 4.4578 - accuracy: 0.7604\n",
      "16/70 [=====>........................] - ETA: 17s - loss: 4.4592 - accuracy: 0.7490\n",
      "16/70 [=====>........................] - ETA: 17s - loss: 4.4592 - accuracy: 0.7490\n",
      "17/70 [======>.......................] - ETA: 16s - loss: 4.4593 - accuracy: 0.7528\n",
      "17/70 [======>.......................] - ETA: 16s - loss: 4.4593 - accuracy: 0.7528\n",
      "18/70 [======>.......................] - ETA: 16s - loss: 4.4598 - accuracy: 0.7535\n",
      "18/70 [======>.......................] - ETA: 16s - loss: 4.4598 - accuracy: 0.7535\n",
      "19/70 [=======>......................] - ETA: 16s - loss: 4.4582 - accuracy: 0.7590\n",
      "19/70 [=======>......................] - ETA: 16s - loss: 4.4582 - accuracy: 0.7590\n",
      "20/70 [=======>......................] - ETA: 16s - loss: 4.4567 - accuracy: 0.7602\n",
      "20/70 [=======>......................] - ETA: 16s - loss: 4.4567 - accuracy: 0.7602\n",
      "21/70 [========>.....................] - ETA: 15s - loss: 4.4549 - accuracy: 0.7641\n",
      "21/70 [========>.....................] - ETA: 15s - loss: 4.4549 - accuracy: 0.7641\n",
      "22/70 [========>.....................] - ETA: 15s - loss: 4.4541 - accuracy: 0.7635\n",
      "22/70 [========>.....................] - ETA: 15s - loss: 4.4541 - accuracy: 0.7635\n",
      "23/70 [========>.....................] - ETA: 15s - loss: 4.4536 - accuracy: 0.7711\n",
      "23/70 [========>.....................] - ETA: 15s - loss: 4.4536 - accuracy: 0.7711\n",
      "24/70 [=========>....................] - ETA: 14s - loss: 4.4522 - accuracy: 0.7728\n",
      "24/70 [=========>....................] - ETA: 14s - loss: 4.4522 - accuracy: 0.7728\n",
      "25/70 [=========>....................] - ETA: 14s - loss: 4.4516 - accuracy: 0.7738\n",
      "25/70 [=========>....................] - ETA: 14s - loss: 4.4516 - accuracy: 0.7738\n",
      "26/70 [==========>...................] - ETA: 14s - loss: 4.4513 - accuracy: 0.7710\n",
      "26/70 [==========>...................] - ETA: 14s - loss: 4.4513 - accuracy: 0.7710\n",
      "27/70 [==========>...................] - ETA: 13s - loss: 4.4501 - accuracy: 0.7749\n",
      "27/70 [==========>...................] - ETA: 13s - loss: 4.4501 - accuracy: 0.7749\n",
      "28/70 [===========>..................] - ETA: 13s - loss: 4.4473 - accuracy: 0.7868\n",
      "28/70 [===========>..................] - ETA: 13s - loss: 4.4473 - accuracy: 0.7868\n",
      "29/70 [===========>..................] - ETA: 13s - loss: 4.4467 - accuracy: 0.7915\n",
      "29/70 [===========>..................] - ETA: 13s - loss: 4.4467 - accuracy: 0.7915\n",
      "30/70 [===========>..................] - ETA: 12s - loss: 4.4468 - accuracy: 0.7901\n",
      "30/70 [===========>..................] - ETA: 12s - loss: 4.4468 - accuracy: 0.7901\n",
      "31/70 [============>.................] - ETA: 12s - loss: 4.4452 - accuracy: 0.7928\n",
      "31/70 [============>.................] - ETA: 12s - loss: 4.4452 - accuracy: 0.7928\n",
      "32/70 [============>.................] - ETA: 12s - loss: 4.4423 - accuracy: 0.8062\n",
      "32/70 [============>.................] - ETA: 12s - loss: 4.4423 - accuracy: 0.8062\n",
      "33/70 [=============>................] - ETA: 12s - loss: 4.4407 - accuracy: 0.8134\n",
      "33/70 [=============>................] - ETA: 12s - loss: 4.4407 - accuracy: 0.8134\n",
      "34/70 [=============>................] - ETA: 11s - loss: 4.4397 - accuracy: 0.8212\n",
      "34/70 [=============>................] - ETA: 11s - loss: 4.4397 - accuracy: 0.8212\n",
      "35/70 [==============>...............] - ETA: 11s - loss: 4.4395 - accuracy: 0.8183\n",
      "35/70 [==============>...............] - ETA: 11s - loss: 4.4395 - accuracy: 0.8183\n",
      "36/70 [==============>...............] - ETA: 11s - loss: 4.4379 - accuracy: 0.8229\n",
      "36/70 [==============>...............] - ETA: 11s - loss: 4.4379 - accuracy: 0.8229\n",
      "37/70 [==============>...............] - ETA: 10s - loss: 4.4376 - accuracy: 0.8231\n",
      "37/70 [==============>...............] - ETA: 10s - loss: 4.4376 - accuracy: 0.8231\n",
      "38/70 [===============>..............] - ETA: 10s - loss: 4.4366 - accuracy: 0.8257\n",
      "38/70 [===============>..............] - ETA: 10s - loss: 4.4366 - accuracy: 0.8257\n",
      "39/70 [===============>..............] - ETA: 9s - loss: 4.4364 - accuracy: 0.8261 \n",
      "39/70 [===============>..............] - ETA: 9s - loss: 4.4364 - accuracy: 0.8261 \n",
      "40/70 [================>.............] - ETA: 9s - loss: 4.4349 - accuracy: 0.8301\n",
      "40/70 [================>.............] - ETA: 9s - loss: 4.4349 - accuracy: 0.8301\n",
      "41/70 [================>.............] - ETA: 9s - loss: 4.4343 - accuracy: 0.8346\n",
      "41/70 [================>.............] - ETA: 9s - loss: 4.4343 - accuracy: 0.8346\n",
      "42/70 [=================>............] - ETA: 9s - loss: 4.4331 - accuracy: 0.8385\n",
      "42/70 [=================>............] - ETA: 9s - loss: 4.4331 - accuracy: 0.8385\n",
      "43/70 [=================>............] - ETA: 8s - loss: 4.4326 - accuracy: 0.8412\n",
      "43/70 [=================>............] - ETA: 8s - loss: 4.4326 - accuracy: 0.8412\n",
      "44/70 [=================>............] - ETA: 8s - loss: 4.4315 - accuracy: 0.8445\n",
      "44/70 [=================>............] - ETA: 8s - loss: 4.4315 - accuracy: 0.8445\n",
      "45/70 [==================>...........] - ETA: 8s - loss: 4.4301 - accuracy: 0.8497\n",
      "45/70 [==================>...........] - ETA: 8s - loss: 4.4301 - accuracy: 0.8497\n",
      "46/70 [==================>...........] - ETA: 7s - loss: 4.4300 - accuracy: 0.8502\n",
      "46/70 [==================>...........] - ETA: 7s - loss: 4.4300 - accuracy: 0.8502\n",
      "47/70 [===================>..........] - ETA: 7s - loss: 4.4281 - accuracy: 0.8547\n",
      "47/70 [===================>..........] - ETA: 7s - loss: 4.4281 - accuracy: 0.8547\n",
      "48/70 [===================>..........] - ETA: 7s - loss: 4.4263 - accuracy: 0.8610\n",
      "48/70 [===================>..........] - ETA: 7s - loss: 4.4263 - accuracy: 0.8610\n",
      "49/70 [====================>.........] - ETA: 6s - loss: 4.4255 - accuracy: 0.8622\n",
      "49/70 [====================>.........] - ETA: 6s - loss: 4.4255 - accuracy: 0.8622\n",
      "50/70 [====================>.........] - ETA: 6s - loss: 4.4246 - accuracy: 0.8644\n",
      "50/70 [====================>.........] - ETA: 6s - loss: 4.4246 - accuracy: 0.8644\n",
      "51/70 [====================>.........] - ETA: 6s - loss: 4.4234 - accuracy: 0.8670\n",
      "51/70 [====================>.........] - ETA: 6s - loss: 4.4234 - accuracy: 0.8670\n",
      "52/70 [=====================>........] - ETA: 5s - loss: 4.4225 - accuracy: 0.8702\n",
      "52/70 [=====================>........] - ETA: 5s - loss: 4.4225 - accuracy: 0.8702\n",
      "53/70 [=====================>........] - ETA: 5s - loss: 4.4216 - accuracy: 0.8732\n",
      "53/70 [=====================>........] - ETA: 5s - loss: 4.4216 - accuracy: 0.8732\n",
      "54/70 [======================>.......] - ETA: 5s - loss: 4.4202 - accuracy: 0.8767\n",
      "54/70 [======================>.......] - ETA: 5s - loss: 4.4202 - accuracy: 0.8767\n",
      "55/70 [======================>.......] - ETA: 4s - loss: 4.4197 - accuracy: 0.8778\n",
      "55/70 [======================>.......] - ETA: 4s - loss: 4.4197 - accuracy: 0.8778\n",
      "56/70 [=======================>......] - ETA: 4s - loss: 4.4187 - accuracy: 0.8792\n",
      "56/70 [=======================>......] - ETA: 4s - loss: 4.4187 - accuracy: 0.8792\n",
      "57/70 [=======================>......] - ETA: 4s - loss: 4.4174 - accuracy: 0.8810\n",
      "57/70 [=======================>......] - ETA: 4s - loss: 4.4174 - accuracy: 0.8810\n",
      "58/70 [=======================>......] - ETA: 3s - loss: 4.4161 - accuracy: 0.8850\n",
      "58/70 [=======================>......] - ETA: 3s - loss: 4.4161 - accuracy: 0.8850\n",
      "59/70 [========================>.....] - ETA: 3s - loss: 4.4153 - accuracy: 0.8867\n",
      "59/70 [========================>.....] - ETA: 3s - loss: 4.4153 - accuracy: 0.8867\n",
      "60/70 [========================>.....] - ETA: 3s - loss: 4.4145 - accuracy: 0.8888\n",
      "60/70 [========================>.....] - ETA: 3s - loss: 4.4145 - accuracy: 0.8888\n",
      "61/70 [=========================>....] - ETA: 2s - loss: 4.4134 - accuracy: 0.8909\n",
      "61/70 [=========================>....] - ETA: 2s - loss: 4.4134 - accuracy: 0.8909\n",
      "62/70 [=========================>....] - ETA: 2s - loss: 4.4121 - accuracy: 0.8934\n",
      "62/70 [=========================>....] - ETA: 2s - loss: 4.4121 - accuracy: 0.8934\n",
      "63/70 [==========================>...] - ETA: 2s - loss: 4.4109 - accuracy: 0.8968\n",
      "63/70 [==========================>...] - ETA: 2s - loss: 4.4109 - accuracy: 0.8968\n",
      "64/70 [==========================>...] - ETA: 1s - loss: 4.4099 - accuracy: 0.8992\n",
      "64/70 [==========================>...] - ETA: 1s - loss: 4.4099 - accuracy: 0.8992\n",
      "65/70 [==========================>...] - ETA: 1s - loss: 4.4091 - accuracy: 0.9005\n",
      "65/70 [==========================>...] - ETA: 1s - loss: 4.4091 - accuracy: 0.9005\n",
      "66/70 [===========================>..] - ETA: 1s - loss: 4.4077 - accuracy: 0.9025\n",
      "66/70 [===========================>..] - ETA: 1s - loss: 4.4077 - accuracy: 0.9025\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 4.4065 - accuracy: 0.9056\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 4.4065 - accuracy: 0.9056\n",
      "68/70 [============================>.] - ETA: 0s - loss: 4.4052 - accuracy: 0.9076\n",
      "68/70 [============================>.] - ETA: 0s - loss: 4.4052 - accuracy: 0.9076\n",
      "69/70 [============================>.] - ETA: 0s - loss: 4.4044 - accuracy: 0.9092\n",
      "69/70 [============================>.] - ETA: 0s - loss: 4.4044 - accuracy: 0.9092\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.4034 - accuracy: 0.9107\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.4034 - accuracy: 0.9107\n",
      "70/70 [==============================] - 24s 335ms/step - loss: 2.2017 - accuracy: 0.4554\n",
      "70/70 [==============================] - 24s 335ms/step - loss: 2.2017 - accuracy: 0.4554\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m Result for TensorflowTrainer_38bb7_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   accuracy: 0.4553571343421936\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   date: 2023-06-30_04-58-24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   hostname: example-cluster-head-vxm8k\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   loss: 2.2017006874084473\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   node_ip: 10.42.0.75\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   pid: 665\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   time_since_restore: 72.40226030349731\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   time_this_iter_s: 23.671977043151855\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   time_total_s: 72.40226030349731\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   timestamp: 1688126303\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   trial_id: 38bb7_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=452)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=879)\u001b[0m Epoch 3/100\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=934)\u001b[0m Epoch 3/100\n",
      " 1/70 [..............................] - ETA: 20s - loss: 4.2792 - accuracy: 1.1562\n",
      " 1/70 [..............................] - ETA: 20s - loss: 4.2792 - accuracy: 1.1562\n",
      " 2/70 [..............................] - ETA: 20s - loss: 4.3121 - accuracy: 1.0703\n",
      " 2/70 [..............................] - ETA: 20s - loss: 4.3121 - accuracy: 1.0703\n",
      " 3/70 [>.............................] - ETA: 20s - loss: 4.3249 - accuracy: 1.0365\n",
      " 3/70 [>.............................] - ETA: 20s - loss: 4.3249 - accuracy: 1.0365\n",
      " 4/70 [>.............................] - ETA: 20s - loss: 4.3312 - accuracy: 1.0234\n",
      " 4/70 [>.............................] - ETA: 20s - loss: 4.3312 - accuracy: 1.0234\n",
      " 5/70 [=>............................] - ETA: 21s - loss: 4.3328 - accuracy: 1.0219\n",
      " 5/70 [=>............................] - ETA: 21s - loss: 4.3328 - accuracy: 1.0219\n",
      " 6/70 [=>............................] - ETA: 20s - loss: 4.3367 - accuracy: 1.0052\n",
      " 6/70 [=>............................] - ETA: 20s - loss: 4.3367 - accuracy: 1.0052\n",
      " 7/70 [==>...........................] - ETA: 19s - loss: 4.3342 - accuracy: 0.9978\n",
      " 7/70 [==>...........................] - ETA: 19s - loss: 4.3342 - accuracy: 0.9978\n",
      " 8/70 [==>...........................] - ETA: 19s - loss: 4.3300 - accuracy: 1.0098\n",
      " 8/70 [==>...........................] - ETA: 19s - loss: 4.3300 - accuracy: 1.0098\n",
      " 9/70 [==>...........................] - ETA: 19s - loss: 4.3261 - accuracy: 1.0278\n",
      " 9/70 [==>...........................] - ETA: 19s - loss: 4.3261 - accuracy: 1.0278\n",
      "10/70 [===>..........................] - ETA: 20s - loss: 4.3246 - accuracy: 1.0266\n",
      "10/70 [===>..........................] - ETA: 20s - loss: 4.3246 - accuracy: 1.0266\n",
      "11/70 [===>..........................] - ETA: 19s - loss: 4.3254 - accuracy: 1.0185\n",
      "11/70 [===>..........................] - ETA: 19s - loss: 4.3254 - accuracy: 1.0185\n",
      "12/70 [====>.........................] - ETA: 18s - loss: 4.3230 - accuracy: 1.0208\n",
      "12/70 [====>.........................] - ETA: 18s - loss: 4.3230 - accuracy: 1.0208\n",
      "13/70 [====>.........................] - ETA: 18s - loss: 4.3196 - accuracy: 1.0312\n",
      "13/70 [====>.........................] - ETA: 18s - loss: 4.3196 - accuracy: 1.0312\n",
      "14/70 [=====>........................] - ETA: 18s - loss: 4.3153 - accuracy: 1.0402\n",
      "14/70 [=====>........................] - ETA: 18s - loss: 4.3153 - accuracy: 1.0402\n",
      "15/70 [=====>........................] - ETA: 17s - loss: 4.3118 - accuracy: 1.0479\n",
      "15/70 [=====>........................] - ETA: 17s - loss: 4.3118 - accuracy: 1.0479\n",
      "16/70 [=====>........................] - ETA: 17s - loss: 4.3098 - accuracy: 1.0488\n",
      "16/70 [=====>........................] - ETA: 17s - loss: 4.3098 - accuracy: 1.0488\n",
      "17/70 [======>.......................] - ETA: 16s - loss: 4.3089 - accuracy: 1.0414\n",
      "17/70 [======>.......................] - ETA: 16s - loss: 4.3089 - accuracy: 1.0414\n",
      "18/70 [======>.......................] - ETA: 16s - loss: 4.3079 - accuracy: 1.0443\n",
      "18/70 [======>.......................] - ETA: 16s - loss: 4.3079 - accuracy: 1.0443\n",
      "19/70 [=======>......................] - ETA: 16s - loss: 4.3076 - accuracy: 1.0452\n",
      "19/70 [=======>......................] - ETA: 16s - loss: 4.3076 - accuracy: 1.0452\n",
      "20/70 [=======>......................] - ETA: 16s - loss: 4.3071 - accuracy: 1.0461\n",
      "20/70 [=======>......................] - ETA: 16s - loss: 4.3071 - accuracy: 1.0461\n",
      "21/70 [========>.....................] - ETA: 16s - loss: 4.3064 - accuracy: 1.0469\n",
      "21/70 [========>.....................] - ETA: 16s - loss: 4.3064 - accuracy: 1.0469\n",
      "22/70 [========>.....................] - ETA: 15s - loss: 4.3057 - accuracy: 1.0518\n",
      "22/70 [========>.....................] - ETA: 15s - loss: 4.3057 - accuracy: 1.0518\n",
      "23/70 [========>.....................] - ETA: 15s - loss: 4.3042 - accuracy: 1.0543\n",
      "23/70 [========>.....................] - ETA: 15s - loss: 4.3042 - accuracy: 1.0543\n",
      "24/70 [=========>....................] - ETA: 15s - loss: 4.3023 - accuracy: 1.0625\n",
      "24/70 [=========>....................] - ETA: 15s - loss: 4.3023 - accuracy: 1.0625\n",
      "25/70 [=========>....................] - ETA: 14s - loss: 4.3016 - accuracy: 1.0612\n",
      "25/70 [=========>....................] - ETA: 14s - loss: 4.3016 - accuracy: 1.0612\n",
      "26/70 [==========>...................] - ETA: 14s - loss: 4.2992 - accuracy: 1.0619\n",
      "26/70 [==========>...................] - ETA: 14s - loss: 4.2992 - accuracy: 1.0619\n",
      "27/70 [==========>...................] - ETA: 13s - loss: 4.2972 - accuracy: 1.0654\n",
      "27/70 [==========>...................] - ETA: 13s - loss: 4.2972 - accuracy: 1.0654\n",
      "28/70 [===========>..................] - ETA: 13s - loss: 4.2958 - accuracy: 1.0681\n",
      "28/70 [===========>..................] - ETA: 13s - loss: 4.2958 - accuracy: 1.0681\n",
      "29/70 [===========>..................] - ETA: 13s - loss: 4.2940 - accuracy: 1.0700\n",
      "29/70 [===========>..................] - ETA: 13s - loss: 4.2940 - accuracy: 1.0700\n",
      "30/70 [===========>..................] - ETA: 13s - loss: 4.2923 - accuracy: 1.0724\n",
      "30/70 [===========>..................] - ETA: 13s - loss: 4.2923 - accuracy: 1.0724\n",
      "31/70 [============>.................] - ETA: 12s - loss: 4.2896 - accuracy: 1.0786\n",
      "31/70 [============>.................] - ETA: 12s - loss: 4.2896 - accuracy: 1.0786\n",
      "32/70 [============>.................] - ETA: 12s - loss: 4.2883 - accuracy: 1.0815\n",
      "32/70 [============>.................] - ETA: 12s - loss: 4.2883 - accuracy: 1.0815\n",
      "33/70 [=============>................] - ETA: 12s - loss: 4.2863 - accuracy: 1.0866\n",
      "33/70 [=============>................] - ETA: 12s - loss: 4.2863 - accuracy: 1.0866\n",
      "34/70 [=============>................] - ETA: 11s - loss: 4.2850 - accuracy: 1.0919\n",
      "34/70 [=============>................] - ETA: 11s - loss: 4.2850 - accuracy: 1.0919\n",
      "35/70 [==============>...............] - ETA: 11s - loss: 4.2836 - accuracy: 1.0920\n",
      "35/70 [==============>...............] - ETA: 11s - loss: 4.2836 - accuracy: 1.0920\n",
      "36/70 [==============>...............] - ETA: 11s - loss: 4.2816 - accuracy: 1.0968\n",
      "36/70 [==============>...............] - ETA: 11s - loss: 4.2816 - accuracy: 1.0968\n",
      "37/70 [==============>...............] - ETA: 10s - loss: 4.2801 - accuracy: 1.0984\n",
      "37/70 [==============>...............] - ETA: 10s - loss: 4.2801 - accuracy: 1.0984\n",
      "38/70 [===============>..............] - ETA: 10s - loss: 4.2786 - accuracy: 1.0979\n",
      "38/70 [===============>..............] - ETA: 10s - loss: 4.2786 - accuracy: 1.0979\n",
      "39/70 [===============>..............] - ETA: 10s - loss: 4.2768 - accuracy: 1.0998\n",
      "39/70 [===============>..............] - ETA: 10s - loss: 4.2768 - accuracy: 1.0998\n",
      "40/70 [================>.............] - ETA: 9s - loss: 4.2739 - accuracy: 1.1055 \n",
      "40/70 [================>.............] - ETA: 9s - loss: 4.2739 - accuracy: 1.1055 \n",
      "41/70 [================>.............] - ETA: 9s - loss: 4.2734 - accuracy: 1.1052\n",
      "41/70 [================>.............] - ETA: 9s - loss: 4.2734 - accuracy: 1.1052\n",
      "42/70 [=================>............] - ETA: 9s - loss: 4.2729 - accuracy: 1.1019\n",
      "42/70 [=================>............] - ETA: 9s - loss: 4.2729 - accuracy: 1.1019\n",
      "43/70 [=================>............] - ETA: 8s - loss: 4.2716 - accuracy: 1.1039\n",
      "43/70 [=================>............] - ETA: 8s - loss: 4.2716 - accuracy: 1.1039\n",
      "44/70 [=================>............] - ETA: 8s - loss: 4.2704 - accuracy: 1.1051\n",
      "44/70 [=================>............] - ETA: 8s - loss: 4.2704 - accuracy: 1.1051\n",
      "45/70 [==================>...........] - ETA: 8s - loss: 4.2699 - accuracy: 1.1045\n",
      "45/70 [==================>...........] - ETA: 8s - loss: 4.2699 - accuracy: 1.1045\n",
      "46/70 [==================>...........] - ETA: 7s - loss: 4.2685 - accuracy: 1.1060\n",
      "46/70 [==================>...........] - ETA: 7s - loss: 4.2685 - accuracy: 1.1060\n",
      "47/70 [===================>..........] - ETA: 7s - loss: 4.2676 - accuracy: 1.1051\n",
      "47/70 [===================>..........] - ETA: 7s - loss: 4.2676 - accuracy: 1.1051\n"
     ]
    }
   ],
   "source": [
    "train_tensorflow_mnist(num_workers=2, use_gpu=True, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9591b-89af-4636-9844-0022414f5cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
