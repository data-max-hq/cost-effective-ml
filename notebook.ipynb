{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c2e6e-af8f-4a52-aef8-e7ce61c6c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray==2.6.1 tensorflow==2.12.1 pyarrow tblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15a5bcb-c809-41a0-8b15-a79a53055c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 11:00:11.689710: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-08 11:00:11.754890: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-08 11:00:11.757280: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 11:00:12.669744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from filelock import FileLock\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from ray.air.result import Result\n",
    "import tensorflow as tf\n",
    "\n",
    "from ray.train.tensorflow import TensorflowTrainer\n",
    "from ray.air.integrations.keras import ReportCheckpointCallback\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "\n",
    "def mnist_dataset(batch_size: int) -> tf.data.Dataset:\n",
    "    with FileLock(os.path.expanduser(\"~/.mnist_lock\")):\n",
    "        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    # The `x` arrays are in uint8 and have values in the [0, 255] range.\n",
    "    # You need to convert them to float32 with values in the [0, 1] range.\n",
    "    x_train = x_train / np.float32(255)\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        .shuffle(60000)\n",
    "        .repeat()\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def build_cnn_model() -> tf.keras.Model:\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(28, 28)),\n",
    "            tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_func(config: dict):\n",
    "    per_worker_batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "    steps_per_epoch = config.get(\"steps_per_epoch\", 70)\n",
    "\n",
    "    tf_config = json.loads(os.environ[\"TF_CONFIG\"])\n",
    "    num_workers = len(tf_config[\"cluster\"][\"worker\"])\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    global_batch_size = per_worker_batch_size * num_workers\n",
    "    multi_worker_dataset = mnist_dataset(global_batch_size)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_cnn_model()\n",
    "        learning_rate = config.get(\"lr\", 0.001)\n",
    "        multi_worker_model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "    history = multi_worker_model.fit(\n",
    "        multi_worker_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[ReportCheckpointCallback()],\n",
    "    )\n",
    "    results = history.history\n",
    "    return results\n",
    "\n",
    "\n",
    "def train_tensorflow_mnist(\n",
    "    num_workers: int = 2, use_gpu: bool = False, epochs: int = 4\n",
    ") -> Result:\n",
    "    config = {\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": epochs}\n",
    "    trainer = TensorflowTrainer(\n",
    "        train_loop_per_worker=train_func,\n",
    "        train_loop_config=config,\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "    )\n",
    "    results = trainer.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7d7155-0829-4b5d-8675-5c865d7198d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f437c40-8f1f-43d3-8fd9-2d83b135931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_env = {\n",
    "    'env_vars': {'RAY_AIR_NEW_OUTPUT': '0'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d4f72-fb11-4bfe-928f-4c58a1cd0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(address=\"ray://example-cluster-head-svc:10001\", runtime_env=runtime_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a10134-96bb-4635-9be9-af1bfa65add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=2, runtime_env=runtime_env)\n",
    "def f():\n",
    "    print(ray.get_gpu_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9793d5-ea59-43cd-9913-0ad58b9e9820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClientObjectRef(c8ef45ccd0112571ffffffffffffffffffffffff0100000001000000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(f pid=254)\u001b[0m [0, 1]\n"
     ]
    }
   ],
   "source": [
    "f.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672995c-a4b6-4715-a2f6-5fadeb7dc507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m View detailed results here: /home/ray/ray_results/TensorflowTrainer_2023-08-08_04-00-31\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m To visualize your results with TensorBoard, run: `tensorboard --logdir /home/ray/ray_results/TensorflowTrainer_2023-08-08_04-00-31`\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n",
      "\u001b[2m\u001b[36m(pid=405)\u001b[0m 2023-08-08 04:00:41.034899: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "\u001b[2m\u001b[36m(pid=405)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=405)\u001b[0m 2023-08-08 04:00:41.273134: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(pid=405)\u001b[0m 2023-08-08 04:00:42.614142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=405)\u001b[0m 2023-08-08 04:00:42.614249: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(pid=405)\u001b[0m 2023-08-08 04:00:42.614259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m Training started with configuration:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m ╭──────────────────────────────────────╮\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m │ Training config                      │\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m ├──────────────────────────────────────┤\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m │ train_loop_config/batch_size      64 │\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m │ train_loop_config/epochs           3 │\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m │ train_loop_config/lr           0.001 │\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m ╰──────────────────────────────────────╯\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=292)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TensorflowTrainer pid=405)\u001b[0m Starting distributed worker processes: ['500 (10.42.1.29)', '539 (10.42.1.29)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:00:51.329339: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:00:51.330414: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:00:51.906566: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:00:52.013202: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:00:54.707832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:00:54.707969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:00:54.707986: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:00:54.818539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:00:54.818689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:00:54.818708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:00:58.736579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:00:58.736620: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:00:58.736240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:00:58.736285: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "   24576/11490434 [..............................] - ETA: 25s\n",
      "   49152/11490434 [..............................] - ETA: 27s\n",
      "  147456/11490434 [..............................] - ETA: 21s\n",
      "  278528/11490434 [..............................] - ETA: 15s\n",
      "  557056/11490434 [>.............................] - ETA: 9s \n",
      " 1064960/11490434 [=>............................] - ETA: 5s\n",
      " 2138112/11490434 [====>.........................] - ETA: 3s\n",
      " 4325376/11490434 [==========>...................] - ETA: 1s\n",
      " 8257536/11490434 [====================>.........] - ETA: 0s\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:01:03.930382: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m op: \"TensorSliceDataset\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m input: \"Placeholder/_0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m input: \"Placeholder/_1\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   key: \"Toutput_types\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       type: DT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       type: DT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   key: \"_cardinality\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     i: 60000\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   key: \"is_files\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   key: \"metadata\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     s: \"\\n\\024TensorSliceDataset:0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   key: \"output_shapes\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   key: \"replicate_on_split\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m experimental_type {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     type_id: TFT_DATASET\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m           type_id: TFT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m           type_id: TFT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:01:03.948677: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m op: \"TensorSliceDataset\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m input: \"Placeholder/_0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m input: \"Placeholder/_1\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   key: \"Toutput_types\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       type: DT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       type: DT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   key: \"_cardinality\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     i: 60000\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   key: \"is_files\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   key: \"metadata\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     s: \"\\n\\024TensorSliceDataset:0\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   key: \"output_shapes\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     list {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         dim {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m           size: 28\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       shape {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m attr {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   key: \"replicate_on_split\"\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   value {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     b: false\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m experimental_type {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     type_id: TFT_DATASET\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       type_id: TFT_PRODUCT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m           type_id: TFT_FLOAT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         type_id: TFT_TENSOR\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         args {\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m           type_id: TFT_INT64\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m         }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m       }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m     }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m   }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m }\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m 2023-08-08 04:01:04.622110: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m 2023-08-08 04:01:04.627913: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=539)\u001b[0m Epoch 1/3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=500)\u001b[0m Epoch 1/3\n",
      " 1/70 [..............................] - ETA: 5:33 - loss: 4.5878 - accuracy: 0.3125\n",
      " 1/70 [..............................] - ETA: 5:38 - loss: 4.5878 - accuracy: 0.3125\n",
      " 2/70 [..............................] - ETA: 20s - loss: 4.5900 - accuracy: 0.2656 \n",
      " 2/70 [..............................] - ETA: 15s - loss: 4.5900 - accuracy: 0.2656 \n",
      " 3/70 [>.............................] - ETA: 19s - loss: 4.5907 - accuracy: 0.2656\n",
      " 3/70 [>.............................] - ETA: 17s - loss: 4.5907 - accuracy: 0.2656\n",
      " 4/70 [>.............................] - ETA: 19s - loss: 4.5930 - accuracy: 0.2656\n",
      " 4/70 [>.............................] - ETA: 17s - loss: 4.5930 - accuracy: 0.2656\n",
      " 5/70 [=>............................] - ETA: 19s - loss: 4.5958 - accuracy: 0.2656\n",
      " 5/70 [=>............................] - ETA: 18s - loss: 4.5958 - accuracy: 0.2656\n",
      " 6/70 [=>............................] - ETA: 18s - loss: 4.5917 - accuracy: 0.2839\n",
      " 6/70 [=>............................] - ETA: 17s - loss: 4.5917 - accuracy: 0.2839\n",
      " 7/70 [==>...........................] - ETA: 18s - loss: 4.5890 - accuracy: 0.2969\n",
      " 7/70 [==>...........................] - ETA: 17s - loss: 4.5890 - accuracy: 0.2969\n",
      " 8/70 [==>...........................] - ETA: 18s - loss: 4.5860 - accuracy: 0.2930\n",
      " 8/70 [==>...........................] - ETA: 17s - loss: 4.5860 - accuracy: 0.2930\n",
      " 9/70 [==>...........................] - ETA: 18s - loss: 4.5830 - accuracy: 0.3003\n",
      " 9/70 [==>...........................] - ETA: 18s - loss: 4.5830 - accuracy: 0.3003\n",
      "10/70 [===>..........................] - ETA: 18s - loss: 4.5811 - accuracy: 0.3063\n",
      "10/70 [===>..........................] - ETA: 18s - loss: 4.5811 - accuracy: 0.3063\n",
      "11/70 [===>..........................] - ETA: 18s - loss: 4.5808 - accuracy: 0.2983\n",
      "11/70 [===>..........................] - ETA: 17s - loss: 4.5808 - accuracy: 0.2983\n",
      "12/70 [====>.........................] - ETA: 17s - loss: 4.5820 - accuracy: 0.2943\n",
      "12/70 [====>.........................] - ETA: 17s - loss: 4.5820 - accuracy: 0.2943\n",
      "13/70 [====>.........................] - ETA: 17s - loss: 4.5806 - accuracy: 0.2957\n",
      "13/70 [====>.........................] - ETA: 17s - loss: 4.5806 - accuracy: 0.2957\n",
      "14/70 [=====>........................] - ETA: 17s - loss: 4.5808 - accuracy: 0.2946\n",
      "14/70 [=====>........................] - ETA: 16s - loss: 4.5808 - accuracy: 0.2946\n",
      "15/70 [=====>........................] - ETA: 16s - loss: 4.5806 - accuracy: 0.2906\n",
      "15/70 [=====>........................] - ETA: 16s - loss: 4.5806 - accuracy: 0.2906\n",
      "16/70 [=====>........................] - ETA: 16s - loss: 4.5787 - accuracy: 0.2891\n",
      "16/70 [=====>........................] - ETA: 15s - loss: 4.5787 - accuracy: 0.2891\n",
      "17/70 [======>.......................] - ETA: 15s - loss: 4.5779 - accuracy: 0.2904\n",
      "17/70 [======>.......................] - ETA: 15s - loss: 4.5779 - accuracy: 0.2904\n",
      "18/70 [======>.......................] - ETA: 15s - loss: 4.5771 - accuracy: 0.2899\n",
      "18/70 [======>.......................] - ETA: 15s - loss: 4.5771 - accuracy: 0.2899\n",
      "19/70 [=======>......................] - ETA: 15s - loss: 4.5761 - accuracy: 0.2944\n",
      "19/70 [=======>......................] - ETA: 15s - loss: 4.5761 - accuracy: 0.2944\n",
      "20/70 [=======>......................] - ETA: 15s - loss: 4.5742 - accuracy: 0.2969\n",
      "20/70 [=======>......................] - ETA: 15s - loss: 4.5742 - accuracy: 0.2969\n",
      "21/70 [========>.....................] - ETA: 15s - loss: 4.5736 - accuracy: 0.2961\n",
      "21/70 [========>.....................] - ETA: 14s - loss: 4.5736 - accuracy: 0.2961\n",
      "22/70 [========>.....................] - ETA: 14s - loss: 4.5712 - accuracy: 0.2983\n",
      "22/70 [========>.....................] - ETA: 14s - loss: 4.5712 - accuracy: 0.2983\n",
      "23/70 [========>.....................] - ETA: 14s - loss: 4.5700 - accuracy: 0.3016\n",
      "23/70 [========>.....................] - ETA: 14s - loss: 4.5700 - accuracy: 0.3016\n",
      "24/70 [=========>....................] - ETA: 13s - loss: 4.5698 - accuracy: 0.3008\n",
      "24/70 [=========>....................] - ETA: 13s - loss: 4.5698 - accuracy: 0.3008\n",
      "25/70 [=========>....................] - ETA: 13s - loss: 4.5690 - accuracy: 0.2969\n",
      "25/70 [=========>....................] - ETA: 13s - loss: 4.5690 - accuracy: 0.2969\n",
      "26/70 [==========>...................] - ETA: 13s - loss: 4.5674 - accuracy: 0.3005\n",
      "26/70 [==========>...................] - ETA: 13s - loss: 4.5674 - accuracy: 0.3005\n",
      "27/70 [==========>...................] - ETA: 13s - loss: 4.5659 - accuracy: 0.3038\n",
      "27/70 [==========>...................] - ETA: 13s - loss: 4.5659 - accuracy: 0.3038\n",
      "28/70 [===========>..................] - ETA: 13s - loss: 4.5651 - accuracy: 0.3013\n",
      "28/70 [===========>..................] - ETA: 13s - loss: 4.5651 - accuracy: 0.3013\n",
      "29/70 [===========>..................] - ETA: 12s - loss: 4.5639 - accuracy: 0.3039\n",
      "29/70 [===========>..................] - ETA: 12s - loss: 4.5639 - accuracy: 0.3039\n",
      "30/70 [===========>..................] - ETA: 12s - loss: 4.5623 - accuracy: 0.3104\n",
      "30/70 [===========>..................] - ETA: 12s - loss: 4.5623 - accuracy: 0.3104\n"
     ]
    }
   ],
   "source": [
    "train_tensorflow_mnist(num_workers=2, use_gpu=True, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9591b-89af-4636-9844-0022414f5cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
